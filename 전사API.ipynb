{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 전사 API.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6QlO8uFvwWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb65481f-38b0-4e57-cfa7-673e2ad5d028"
      },
      "source": [
        "!pip install pydub\n",
        "!pip install SpeechRecognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.24.1\n",
            "Collecting SpeechRecognition\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 112kB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD9pBs7ev-Yx"
      },
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_silence\n",
        "from pydub.silence import detect_nonsilent\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import librosa\n",
        "import sklearn\n",
        "import speech_recognition as sr\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrfTmm39wBT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b23565-24c5-40f4-9194-605c6ec7ab4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0MhBOshwCc1"
      },
      "source": [
        "filler_determine_model = load_model('/content/drive/My Drive/졸프/0726Data/filler_determine_model_by_train2.h5')\n",
        "filler_classifier_model = load_model('/content/drive/My Drive/졸프/0726Data/filler_classifier_by_train2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMs0AbDzwVP5"
      },
      "source": [
        "pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i-a.shape[0])))\n",
        "pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
        "\n",
        "frame_length = 0.025\n",
        "frame_stride = 0.0010"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMEmmT90H4-K"
      },
      "source": [
        "#adjust target amplitude\n",
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5-Xjt_Kwh01"
      },
      "source": [
        "def predict_filler(audio_file):\n",
        "  # 추임새 판별을 위한 임시 음성 파일 생성\n",
        "  audio_file.export(\"temp.wav\", format=\"wav\")\n",
        "\n",
        "  wav, sr = librosa.load(\"temp.wav\", sr=16000)\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(wav)\n",
        "  padded_mfcc = pad2d(mfcc, 40)\n",
        "  padded_mfcc = np.expand_dims(padded_mfcc, 0)\n",
        "\n",
        "  result = filler_determine_model.predict(padded_mfcc)\n",
        "\n",
        "  # 판별 완료된 음성 파일 삭제\n",
        "  os.remove(\"temp.wav\")\n",
        "\n",
        "  if result[0][0] >= result[0][1]: # 추임새\n",
        "    return 0 \n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK9xFxBZxPSw"
      },
      "source": [
        "def predict_filler_type(audio_file):\n",
        "  # 추임새 종류 판별을 위한 임시 음성 파일 생성\n",
        "  audio_file.export(\"temp.wav\", format=\"wav\")\n",
        "\n",
        "  wav, sr = librosa.load(\"temp.wav\", sr=16000)\n",
        "  input_nfft = int(round(sr*frame_length))\n",
        "  input_stride = int(round(sr*frame_stride))\n",
        "\n",
        "  mfcc = librosa.feature.mfcc(wav)\n",
        "  padded_mfcc = pad2d(mfcc, 40)\n",
        "  padded_mfcc = np.expand_dims(padded_mfcc, 0)\n",
        "\n",
        "  result = filler_classifier_model.predict(padded_mfcc)\n",
        "\n",
        "  # 판별 완료된 음성 파일 삭제\n",
        "  os.remove(\"temp.wav\")\n",
        "\n",
        "  return np.argmax(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DEHThTR6Ad1"
      },
      "source": [
        "def shorter_filler(json_result, audio_file, min_silence_len, start_time, non_silence_start):\n",
        "  \n",
        "  # 침묵 길이를 더 짧게\n",
        "  min_silence_length = (int)(min_silence_len/1.2)\n",
        "\n",
        "  intervals = detect_nonsilent(audio_file,\n",
        "                              min_silence_len=min_silence_length,\n",
        "                              silence_thresh=-32.64\n",
        "                              )\n",
        "  \n",
        "  for interval in intervals:\n",
        "\n",
        "    interval_audio = audio_file[interval[0]:interval[1]]\n",
        "\n",
        "    # padding 40 길이 이상인 경우 더 짧게\n",
        "    if (interval[1]-interval[0] >= 460):\n",
        "      non_silence_start = shorter_filler(json_result, interval_audio, min_silence_length, interval[0]+start_time, non_silence_start)\n",
        "\n",
        "    else: # padding 40 길이보다 짧은 경우 predict\n",
        "      if predict_filler(interval_audio) == 0 : # 추임새인 경우\n",
        "        json_result.append({'start':non_silence_start,'end':start_time+interval[0],'tag':'1000'}) # tag: 1000 means non-slience\n",
        "        non_silence_start = start_time + interval[0]\n",
        "        \n",
        "        # 추임새 tagging\n",
        "        json_result.append({'start':start_time+interval[0],'end':start_time+interval[1],'tag':'1111'}) # tag: 1111 means filler word\n",
        "        \n",
        "    \n",
        "  return non_silence_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d9URQmDxedV"
      },
      "source": [
        "def create_json(audio_file):\n",
        "  intervals_jsons = []\n",
        "\n",
        "  min_silence_length = 70\n",
        "  intervals = detect_nonsilent(audio_file,\n",
        "                              min_silence_len=min_silence_length,\n",
        "                              silence_thresh=-32.64\n",
        "                              )\n",
        "  \n",
        "  if intervals[0][0] != 0:\n",
        "    intervals_jsons.append({'start':0,'end':intervals[0][0],'tag':'0000'}) # tag: 0000 means silence\n",
        "    \n",
        "  non_silence_start = intervals[0][0]\n",
        "  before_silence_start = intervals[0][1]\n",
        "\n",
        "  for interval in intervals:\n",
        "    interval_audio = audio_file[interval[0]:interval[1]]\n",
        "\n",
        "     # 800ms초 이상의 공백 부분 처리\n",
        "    if (interval[0]-before_silence_start) >= 800:\n",
        "      intervals_jsons.append({'start':non_silence_start,'end':before_silence_start+200,'tag':'1000'}) # tag: 1000 means non-slience\n",
        "      non_silence_start = interval[0]-200\n",
        "      intervals_jsons.append({'start':before_silence_start,'end':interval[0],'tag':'0000'}) # tag: 0000 means slience\n",
        "\n",
        "    if predict_filler(interval_audio) == 0 : # 추임새인 경우\n",
        "      if len(interval_audio) <= 460:\n",
        "        intervals_jsons.append({'start':non_silence_start,'end':interval[0],'tag':'1000'}) # tag: 1000 means non-slience\n",
        "        non_silence_start = interval[0]\n",
        "        intervals_jsons.append({'start':interval[0],'end':interval[1],'tag':'1111'})\n",
        "      else:\n",
        "        non_silence_start = shorter_filler(intervals_jsons, interval_audio, min_silence_length, interval[0], non_silence_start)\n",
        "    \n",
        "    before_silence_start = interval[1]\n",
        "\n",
        "  if non_silence_start != len(audio_file):\n",
        "    intervals_jsons.append({'start':non_silence_start,'end':len(audio_file),'tag':'1000'})\n",
        "\n",
        "  return intervals_jsons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-76aios1CVl"
      },
      "source": [
        "def STT_with_json(audio_file, jsons):\n",
        "  first_silence = 0\n",
        "  num = 0\n",
        "  unrecognizable_start = 0\n",
        "  r = sr.Recognizer()\n",
        "  transcript_json = []\n",
        "  statistics_filler_json = []\n",
        "  statistics_silence_json = []\n",
        "  filler_1 = 0\n",
        "  filler_2 = 0\n",
        "  filler_3 = 0\n",
        "  audio_total_length = audio_file.duration_seconds\n",
        "  silence_interval = 0\n",
        "  for json in jsons :\n",
        "    if json['tag'] == '0000':\n",
        "      # 통역 개시 지연시간\n",
        "      if num == 0:\n",
        "        first_silence = first_silence + (json['end']-json['start'])/1000\n",
        "      else:\n",
        "        silence_interval = silence_interval + (json['end']-json['start'])/1000\n",
        "        silence = \"(\" + str(round((json['end']-json['start'])/1000)) + \"초)..\"\n",
        "        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'0000','result':silence})\n",
        "\n",
        "    elif json['tag'] == '1111':\n",
        "      # 통역 개시 지연시간\n",
        "      if num == 0:\n",
        "        silence = \"(\" + str(round(first_silence)) + \"초)..\"\n",
        "        transcript_json.append({'start':0,'end':json['start'],'tag':'0000','result':silence})\n",
        "        first_silence_interval = first_silence\n",
        "      # 추임새(어, 음, 그) 구분  \n",
        "      filler_type = predict_filler_type(audio_file[json['start']:json['end']])\n",
        "      if filler_type == 0 :\n",
        "        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1001','result':'어(추임새)'})\n",
        "        filler_1 = filler_1 + 1\n",
        "      elif filler_type == 1:\n",
        "        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1010','result':'음(추임새)'})\n",
        "        filler_2 = filler_2 + 1\n",
        "      else:\n",
        "        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1100','result':'그(추임새)'})\n",
        "        filler_3 = filler_3 + 1\n",
        "      num = num + 1\n",
        "   \n",
        "    elif json['tag'] == '1000':\n",
        "\n",
        "      # 인식불가 처리\n",
        "      if unrecognizable_start != 0:\n",
        "        audio_file[unrecognizable_start:json['end']].export(\"temp.wav\", format=\"wav\")\n",
        "      else:\n",
        "        audio_file[json['start']:json['end']].export(\"temp.wav\", format=\"wav\")\n",
        "      temp_audio_file = sr.AudioFile('temp.wav')\n",
        "      with temp_audio_file as source:\n",
        "        audio = r.record(source)\n",
        "      try :\n",
        "        stt = r.recognize_google(audio_data = audio, language = \"ko-KR\")\n",
        "        # 통역 개시 지연시간\n",
        "        if num == 0:\n",
        "          silence = \"(\" + str(round(first_silence)) + \"초)..\"\n",
        "          transcript_json.append({'start':0,'end':json['start'],'tag':'0000','result':silence})\n",
        "          first_silence_interval = first_silence\n",
        "        if unrecognizable_start != 0:\n",
        "          transcript_json.append({'start':unrecognizable_start,'end':json['end'],'tag':'1000','result':stt})\n",
        "        else:\n",
        "          transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1000','result':stt})\n",
        "        unrecognizable_start = 0\n",
        "        num = num + 1\n",
        "      except:\n",
        "        if unrecognizable_start == 0:\n",
        "          unrecognizable_start = json['start']\n",
        "\n",
        "  statistics_filler_json.append({'어':filler_1, '음':filler_2, '그':filler_3})\n",
        "  statistics_silence_json.append({'통역개시지연시간':100 * first_silence_interval/audio_total_length, '침묵시간':100 * silence_interval/audio_total_length, '발화시간':100 * (audio_total_length - first_silence - silence_interval)/audio_total_length})\n",
        "  return transcript_json, statistics_filler_json, statistics_silence_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiE6rc3u59Os"
      },
      "source": [
        "def make_transcript(audio_file_path):\n",
        "  audio = AudioSegment.from_mp3(audio_file_path)\n",
        "  normalized_audio = match_target_amplitude(audio, -20.0)\n",
        "  intervals_jsons = create_json(normalized_audio)\n",
        "  transcript_json = STT_with_json(normalized_audio, intervals_jsons)\n",
        "\n",
        "  return transcript_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L1LJycc6ymW"
      },
      "source": [
        "transcript_json, statistics_filler_json, statistics_silence_json = make_transcript(\"/content/drive/My Drive/졸프/code/순차통역예시1.mp3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOGloHR_Gi6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db243160-7965-428b-b1cc-cf2727d42e45"
      },
      "source": [
        "for transcript in transcript_json:\n",
        "  print(transcript)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'start': 0, 'end': 15155, 'tag': '0000', 'result': '(15초)..'}\n",
            "{'start': 10679, 'end': 32420, 'tag': '1000', 'result': '게이오기주쿠대학 야마모토 다치고 교수는 헌법 13조라는 관점에서 문제를 제기하고 있습니다 일본의 헌법 13조에 따르면 모든 국민은 개인으로서 존중받아야 권리가 있다라고 쓰여 있는데요'}\n",
            "{'start': 32220, 'end': 34465, 'tag': '0000', 'result': '(2초)..'}\n",
            "{'start': 34265, 'end': 47601, 'tag': '1000', 'result': '디지털 학습을 한 ai로 개인의 실체가 개인의 그런 정보에 점점 더 접근해야하는 프로파일링 기술이 점점 더 발전하고 있습니다'}\n",
            "{'start': 47401, 'end': 48704, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 48504, 'end': 52989, 'tag': '1000', 'result': '이는 인재채용을 할 때나 신용등급을'}\n",
            "{'start': 52789, 'end': 54352, 'tag': '0000', 'result': '(2초)..'}\n",
            "{'start': 54603, 'end': 55022, 'tag': '1001', 'result': '어(추임새)'}\n",
            "{'start': 54152, 'end': 58871, 'tag': '1000', 'result': '파악하는 등 금융 서비스에서도 활용이 가능하다'}\n",
            "{'start': 58671, 'end': 60292, 'tag': '0000', 'result': '(2초)..'}\n",
            "{'start': 60092, 'end': 61538, 'tag': '1000', 'result': '가능하면서'}\n",
            "{'start': 61338, 'end': 62465, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 62465, 'end': 62796, 'tag': '1001', 'result': '어(추임새)'}\n",
            "{'start': 62265, 'end': 65531, 'tag': '1000', 'result': '은영 영역이 대단히 넓습니다'}\n",
            "{'start': 65331, 'end': 66777, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 66577, 'end': 70800, 'tag': '1000', 'result': '그러나 이런 식으로 개인을 분류하기 시작하면'}\n",
            "{'start': 70600, 'end': 71734, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 71534, 'end': 74805, 'tag': '1000', 'result': '시작하면 점점 개인의'}\n",
            "{'start': 74605, 'end': 75521, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 75321, 'end': 79292, 'tag': '1000', 'result': '이런 정보를 기반으로 개인을 차별하는 시대가'}\n",
            "{'start': 79092, 'end': 79969, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 79769, 'end': 81508, 'tag': '1000', 'result': '다가올 수도 있다고'}\n",
            "{'start': 81308, 'end': 82300, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 82100, 'end': 83672, 'tag': '1000', 'result': '야마모토 교수는'}\n",
            "{'start': 83472, 'end': 84683, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 84483, 'end': 86114, 'tag': '1000', 'result': '염려하고 있습니다'}\n",
            "{'start': 85914, 'end': 87628, 'tag': '0000', 'result': '(2초)..'}\n",
            "{'start': 87428, 'end': 90494, 'tag': '1000', 'result': '우리가 AI를 통해서 얻을 수 있는 것은'}\n",
            "{'start': 90294, 'end': 91513, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 91313, 'end': 93590, 'tag': '1000', 'result': '디지털화를'}\n",
            "{'start': 93390, 'end': 97143, 'tag': '0000', 'result': '(4초)..'}\n",
            "{'start': 96943, 'end': 99022, 'tag': '1000', 'result': '어 디지털화를 통해서'}\n",
            "{'start': 98822, 'end': 99855, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 99655, 'end': 101424, 'tag': '1000', 'result': '예측을 하고'}\n",
            "{'start': 101224, 'end': 102106, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 101906, 'end': 105901, 'tag': '1000', 'result': '디지털화를 통한 예측과 확률입니다'}\n",
            "{'start': 105701, 'end': 107938, 'tag': '0000', 'result': '(2초)..'}\n",
            "{'start': 107738, 'end': 109897, 'tag': '1000', 'result': '이 사람이 실제로'}\n",
            "{'start': 109697, 'end': 110671, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 110972, 'end': 112118, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 110471, 'end': 117127, 'tag': '1000', 'result': '거기에 딱 들어 맞는지는 모르지만이 사람은 이런 사람이다'}\n",
            "{'start': 117127, 'end': 117335, 'tag': '1001', 'result': '어(추임새)'}\n",
            "{'start': 117719, 'end': 121406, 'tag': '0000', 'result': '(4초)..'}\n",
            "{'start': 117127, 'end': 122811, 'tag': '1000', 'result': '추측을 하고'}\n",
            "{'start': 122611, 'end': 126515, 'tag': '0000', 'result': '(4초)..'}\n",
            "{'start': 126315, 'end': 136796, 'tag': '1000', 'result': '추측을 할 수 있는 그런 시대가 도래한 것이지요 개인 화라는 간판을 내걸고 아이티는'}\n",
            "{'start': 136596, 'end': 137461, 'tag': '0000', 'result': '(1초)..'}\n",
            "{'start': 137261, 'end': 146100, 'tag': '1000', 'result': '아이야 기술은 힘을 얻었지만이 기술이 개인을 경시하는 풍조를 나을 수도 있겠습니다'}\n",
            "{'start': 145900, 'end': 164445, 'tag': '0000', 'result': '(19초)..'}\n",
            "{'start': 164452, 'end': 167240, 'tag': '0000', 'result': '(3초)..'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x388PYt6GvJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61c0566-5bb7-47aa-f753-dd4cdddb221b"
      },
      "source": [
        "statistics_filler_json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'그': 0, '어': 3, '음': 0}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLhqPUOvVEos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d21fe7-ccc0-446f-97ac-1798f36e003a"
      },
      "source": [
        "statistics_silence_json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'발화시간': 57.29785246980489,\n",
              "  '침묵시간': 33.895918821616604,\n",
              "  '통역개시지연시간': 8.806228708578509}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FTmeBWDOk-g"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}